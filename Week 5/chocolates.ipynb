{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20388\\2884515495.py:39: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  choc_data['maker_location'] = choc_data['maker_location']\\\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20388\\2884515495.py:74: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  choc_data['specific_origin'] = choc_data['specific_origin'].str.replace('.', '').apply(cleanup_spelling_abbrev)\n",
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_20388\\2884515495.py:83: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  choc_data['broad_origin'] = choc_data['broad_origin'].str.replace('.', '').apply(cleanup_spelling_abbrev)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>review_date</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>1876</td>\n",
       "      <td>2016</td>\n",
       "      <td>63.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Sao Tome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>1676</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>1680</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>1704</td>\n",
       "      <td>2015</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maker specific_origin  reference_number  review_date  cocoa_percent  \\\n",
       "0  A. Morin     Agua Grande              1876         2016          63.00   \n",
       "1  A. Morin           Kpime              1676         2015          70.00   \n",
       "2  A. Morin          Atsane              1676         2015          70.00   \n",
       "3  A. Morin           Akata              1680         2015          70.00   \n",
       "4  A. Morin          Quilla              1704         2015          70.00   \n",
       "\n",
       "  maker_location  rating bean_type broad_origin  \n",
       "0         France    3.75     Blend     Sao Tome  \n",
       "1         France    2.75     Blend         Togo  \n",
       "2         France    3.00     Blend         Togo  \n",
       "3         France    3.50     Blend         Togo  \n",
       "4         France    3.50     Blend         Peru  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Run to load and clean the dataset\n",
    "%reset -f\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import numpy.linalg as nla\n",
    "import pandas as pd\n",
    "import re\n",
    "import six\n",
    "from os.path import join\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "\n",
    "# Set the output display to have one digit for decimal places and limit it to\n",
    "# printing 15 rows.\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "pd.options.display.max_rows = 15\n",
    "\n",
    "choc_data = pd.read_csv(\"https://download.mlcc.google.com/mledu-datasets/flavors_of_cacao.csv\", sep=\",\", encoding='latin-1')\n",
    "\n",
    "# We can rename the columns.\n",
    "choc_data.columns = ['maker', 'specific_origin', 'reference_number', 'review_date', 'cocoa_percent', 'maker_location', 'rating', 'bean_type', 'broad_origin']\n",
    "\n",
    "# choc_data.dtypes\n",
    "\n",
    "# Replace empty/null values with \"Blend\"\n",
    "choc_data['bean_type'] = choc_data['bean_type'].fillna('Blend')\n",
    "\n",
    "#@title Cast bean_type to string to remove leading 'u'\n",
    "choc_data['bean_type'] = choc_data['bean_type'].astype(str)\n",
    "choc_data['cocoa_percent'] = choc_data['cocoa_percent'].str.strip('%')\n",
    "choc_data['cocoa_percent'] = pd.to_numeric(choc_data['cocoa_percent'])\n",
    "\n",
    "#@title Correct spelling mistakes, and replace city with country name\n",
    "choc_data['maker_location'] = choc_data['maker_location']\\\n",
    ".str.replace('Amsterdam', 'Holland')\\\n",
    ".str.replace('U.K.', 'England')\\\n",
    ".str.replace('Niacragua', 'Nicaragua')\\\n",
    ".str.replace('Domincan Republic', 'Dominican Republic')\n",
    "\n",
    "# Adding this so that Holland and Netherlands map to the same country.\n",
    "choc_data['maker_location'] = choc_data['maker_location']\\\n",
    ".str.replace('Holland', 'Netherlands')\n",
    "\n",
    "def cleanup_spelling_abbrev(text):\n",
    "    replacements = [\n",
    "        ['-', ', '], ['/ ', ', '], ['/', ', '], ['\\(', ', '], [' and', ', '], [' &', ', '], ['\\)', ''],\n",
    "        ['Dom Rep|DR|Domin Rep|Dominican Rep,|Domincan Republic', 'Dominican Republic'],\n",
    "        ['Mad,|Mad$', 'Madagascar, '],\n",
    "        ['PNG', 'Papua New Guinea, '],\n",
    "        ['Guat,|Guat$', 'Guatemala, '],\n",
    "        ['Ven,|Ven$|Venez,|Venez$', 'Venezuela, '],\n",
    "        ['Ecu,|Ecu$|Ecuad,|Ecuad$', 'Ecuador, '],\n",
    "        ['Nic,|Nic$', 'Nicaragua, '],\n",
    "        ['Cost Rica', 'Costa Rica'],\n",
    "        ['Mex,|Mex$', 'Mexico, '],\n",
    "        ['Jam,|Jam$', 'Jamaica, '],\n",
    "        ['Haw,|Haw$', 'Hawaii, '],\n",
    "        ['Gre,|Gre$', 'Grenada, '],\n",
    "        ['Tri,|Tri$', 'Trinidad, '],\n",
    "        ['C Am', 'Central America'],\n",
    "        ['S America', 'South America'],\n",
    "        [', $', ''], [',  ', ', '], [', ,', ', '], ['\\xa0', ' '],[',\\s+', ','],\n",
    "        [' Bali', ',Bali']\n",
    "    ]\n",
    "    for i, j in replacements:\n",
    "        text = re.sub(i, j, text)\n",
    "    return text\n",
    "\n",
    "choc_data['specific_origin'] = choc_data['specific_origin'].str.replace('.', '').apply(cleanup_spelling_abbrev)\n",
    "\n",
    "#@title Cast specific_origin to string\n",
    "choc_data['specific_origin'] = choc_data['specific_origin'].astype(str)\n",
    "\n",
    "#@title Replace null-valued fields with the same value as for specific_origin\n",
    "choc_data['broad_origin'] = choc_data['broad_origin'].fillna(choc_data['specific_origin'])\n",
    "\n",
    "#@title Clean up spelling mistakes and deal with abbreviations\n",
    "choc_data['broad_origin'] = choc_data['broad_origin'].str.replace('.', '').apply(cleanup_spelling_abbrev)\n",
    "\n",
    "# Change 'Trinitario, Criollo' to \"Criollo, Trinitario\"\n",
    "# Check with choc_data['bean_type'].unique()\n",
    "choc_data.loc[choc_data['bean_type'].isin(['Trinitario, Criollo']),'bean_type'] = \"Criollo, Trinitario\"\n",
    "# Confirm with choc_data[choc_data['bean_type'].isin(['Trinitario, Criollo'])]\n",
    "\n",
    "# Fix chocolate maker names\n",
    "choc_data.loc[choc_data['maker']=='Shattel','maker'] = 'Shattell'\n",
    "choc_data['maker'] = choc_data['maker'].str.replace(u'Na\\xef\\xbf\\xbdve','Naive')\n",
    "\n",
    "choc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>maker</th>\n",
       "      <th>specific_origin</th>\n",
       "      <th>cocoa_percent</th>\n",
       "      <th>maker_location</th>\n",
       "      <th>rating</th>\n",
       "      <th>bean_type</th>\n",
       "      <th>broad_origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Agua Grande</td>\n",
       "      <td>63.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Sao Tome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Kpime</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>2.75</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Atsane</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.00</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Akata</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A. Morin</td>\n",
       "      <td>Quilla</td>\n",
       "      <td>70.00</td>\n",
       "      <td>France</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Blend</td>\n",
       "      <td>Peru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      maker specific_origin  cocoa_percent maker_location  rating bean_type  \\\n",
       "0  A. Morin     Agua Grande          63.00         France    3.75     Blend   \n",
       "1  A. Morin           Kpime          70.00         France    2.75     Blend   \n",
       "2  A. Morin          Atsane          70.00         France    3.00     Blend   \n",
       "3  A. Morin           Akata          70.00         France    3.50     Blend   \n",
       "4  A. Morin          Quilla          70.00         France    3.50     Blend   \n",
       "\n",
       "  broad_origin  \n",
       "0     Sao Tome  \n",
       "1         Togo  \n",
       "2         Togo  \n",
       "3         Togo  \n",
       "4         Peru  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choc_data.drop(columns=['review_date','reference_number'],inplace=True)\n",
    "choc_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ build model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SimilarityModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20388\\3568995093.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'------ build model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m   similarity_model = SimilarityModel(\n\u001b[0m\u001b[0;32m     34\u001b[0m       \u001b[0mchoc_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m       \u001b[0minput_feature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_feature_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'SimilarityModel' is not defined"
     ]
    }
   ],
   "source": [
    "#@title Training a DNN Similarity Model\n",
    "\n",
    "# Define some constants related to this dataset.\n",
    "sparse_feature_names = ('maker', 'maker_location', 'broad_origin',\n",
    "                        'specific_origin', 'bean_type')\n",
    "dense_feature_names = ('reference_number', 'review_date', 'cocoa_percent',\n",
    "                       'rating')\n",
    "\n",
    "# Set of features used as input to the similarity model.\n",
    "input_feature_names = ('maker', 'maker_location', 'broad_origin',\n",
    "                       'cocoa_percent', 'bean_type','rating', )\n",
    "# Set of features used as output to the similarity model.\n",
    "output_feature_names = ['rating']  #@param\n",
    "\n",
    "# As a rule of thumb, a reasonable choice for the embedding dimension of a\n",
    "# sparse feature column is the log2 of the cardinality of its vocabulary.\n",
    "# sparse_input_feature_embedding_dims = { 'maker': 9, 'maker_location': 6, ... }\n",
    "default_embedding_dims = {\n",
    "    sfn: int(round(math.log(choc_data[sfn].nunique()) / math.log(2)))\n",
    "    for sfn in set(sparse_feature_names).intersection(input_feature_names)\n",
    "}\n",
    "# Dictionary mapping each sparse input feature to the dimension of its embedding\n",
    "# space.\n",
    "sparse_input_feature_embedding_dims = default_embedding_dims  # can be a param\n",
    "\n",
    "# Weight of the L2 regularization applied to the top embedding layer.\n",
    "l2_regularization = 10  #@param\n",
    "# List of dimensions of the hidden layers of the deep neural network.\n",
    "hidden_dims = [20, 10]  #@param\n",
    "\n",
    "print('------ build model')\n",
    "with tf.Graph().as_default():\n",
    "  similarity_model = SimilarityModel(\n",
    "      choc_data,\n",
    "      input_feature_names=input_feature_names,\n",
    "      output_feature_names=output_feature_names,\n",
    "      dense_feature_names=dense_feature_names,\n",
    "      sparse_input_feature_embedding_dims=sparse_input_feature_embedding_dims,\n",
    "      hidden_dims=hidden_dims,\n",
    "      l2_regularization=l2_regularization,\n",
    "      batch_size=100,\n",
    "      use_bias=True,\n",
    "      inspect=True)\n",
    "\n",
    "print('------ train model')\n",
    "similarity_model.train(\n",
    "    num_iterations=1000,\n",
    "    learning_rate=0.1,\n",
    "    optimizer=tf.train.AdagradOptimizer)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run cell to set up functions\n",
    "def dfSimilarity(df,centroids):\n",
    "  ### dfSimilarity = Calculate similarities for dataframe input\n",
    "  ### We need to calculate ||a-b||^2 = |a|^2 + |b|^2 - 2*|a|*|b|\n",
    "  ### Implement this with matrix operations\n",
    "  ### See the Appendix for further explanation\n",
    "  numPoints = len(df.index)\n",
    "  numCentroids = len(centroids.index)\n",
    "  ## Strictly speaking, we don't need to calculate the norm of points\n",
    "  # because it adds a constant bias to distances\n",
    "  # But calculating it so that the similarity doesn't go negative\n",
    "  # And that we expect similarities in [0,1] which aids debugging\n",
    "  pointNorms = np.square(nla.norm(df,axis=1))\n",
    "  pointNorms = np.reshape(pointNorms,[numPoints,1])\n",
    "  ## Calculate the norm of centroids\n",
    "  centroidNorms = np.square(nla.norm(centroids,axis=1))\n",
    "  centroidNorms = np.reshape(centroidNorms,(1,numCentroids))\n",
    "  ## Calculate |a|^2 + |b|^2 - 2*|a|*|b|\n",
    "  similarities = pointNorms + centroidNorms - 2.0*np.dot(df,np.transpose(centroids))\n",
    "  # Divide by the number of features\n",
    "  # Which is 10 because the one-hot encoding means the \"Maker\" and \"Bean\" are\n",
    "  # weighted twice\n",
    "  similarities = similarities/10.0\n",
    "  # numerical artifacts lead to negligible but negative values that go to NaN on the root\n",
    "  similarities = similarities.clip(min=0.0)\n",
    "  # Square root since it's ||a-b||^2\n",
    "  similarities = np.sqrt(similarities)\n",
    "  return similarities\n",
    "\n",
    "def initCentroids(df,k,feature_cols):\n",
    "  # Pick 'k' examples are random to serve as initial centroids\n",
    "  limit = len(df.index)\n",
    "  centroids_key = np.random.randint(0,limit-1,k)\n",
    "  centroids = df.loc[centroids_key,feature_cols].copy(deep=True)\n",
    "  # the indexes get copied over so reset them\n",
    "  centroids.reset_index(drop=True,inplace=True)\n",
    "  return centroids\n",
    "\n",
    "def pt2centroid(df,centroids,feature_cols):\n",
    "  ### Calculate similarities between all points and centroids\n",
    "  ### And assign points to the closest centroid + save that distance\n",
    "  numCentroids = len(centroids.index)\n",
    "  numExamples = len(df.index)\n",
    "  # dfSimilarity = Calculate similarities for dataframe input\n",
    "  dist = dfSimilarity(df.loc[:,feature_cols],centroids.loc[:,feature_cols])\n",
    "  df.loc[:,'centroid'] = np.argmin(dist,axis=1) # closest centroid\n",
    "  df.loc[:,'pt2centroid'] = np.min(dist,axis=1) # minimum distance\n",
    "  return df\n",
    "\n",
    "def recomputeCentroids(df,centroids,feature_cols):\n",
    "  ### For every centroid, recompute it as an average of the points\n",
    "  ### assigned to it\n",
    "  numCentroids = len(centroids.index)\n",
    "  for cen in range(numCentroids):\n",
    "    dfSubset = df.loc[df['centroid'] == cen, feature_cols] # all points for centroid\n",
    "    if not(dfSubset.empty): # if there are points assigned to the centroid\n",
    "      clusterAvg = np.sum(dfSubset)/len(dfSubset.index)\n",
    "      centroids.loc[cen] = clusterAvg\n",
    "  return centroids\n",
    "\n",
    "def kmeans(df,k,feature_cols,verbose):\n",
    "  flagConvergence = False\n",
    "  maxIter = 100\n",
    "  iter = 0                      # ensure kmeans doesn't run for ever\n",
    "  centroids = initCentroids(df,k,feature_cols)\n",
    "  while not(flagConvergence):\n",
    "    iter += 1\n",
    "    #Save old mapping of points to centroids\n",
    "    oldMapping = df['centroid'].copy(deep=True)\n",
    "    # Perform k-means\n",
    "    df = pt2centroid(df,centroids,feature_cols)\n",
    "    centroids = recomputeCentroids(df,centroids,feature_cols)\n",
    "    # Check convergence by comparing [oldMapping, newMapping]\n",
    "    newMapping = df['centroid']\n",
    "    flagConvergence = all(oldMapping == newMapping)\n",
    "    if verbose == 1:\n",
    "      print(\"Total distance:\" + str(np.sum(df['pt2centroid'])))\n",
    "    if (iter > maxIter):\n",
    "      print('k-means did not converge! Reached maximum iteration limit of ' \\\n",
    "            + str(maxIter) + '.')\n",
    "      sys.exit()\n",
    "      return\n",
    "  print('k-means converged for ' + str(k) + ' clusters' + \\\n",
    "        ' after ' + str(iter) + ' iterations!')\n",
    "  return [df,centroids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarity_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20388\\1561769244.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Extract embeddings into a dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mchoc_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msimilarity_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mchoc_embed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchoc_embed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'similarity_model' is not defined"
     ]
    }
   ],
   "source": [
    "k = 160 #@param\n",
    "\n",
    "# Extract embeddings into a dataframe\n",
    "choc_embed = similarity_model.embeddings\n",
    "choc_embed = pd.DataFrame(choc_embed)\n",
    "\n",
    "feature_cols = choc_embed.columns.values # save original columns\n",
    "# initialize every point to an impossible value, the k+1 cluster\n",
    "choc_embed['centroid'] = k\n",
    "# init the point to centroid distance to an impossible value \"2\" (>1)\n",
    "choc_embed['pt2centroid'] = 2\n",
    "[choc_embed,centroids] = kmeans(choc_embed,k,feature_cols,1)\n",
    "print(\"Data for the first few chocolates, with 'centroid' and 'pt2centroid' on the extreme right:\")\n",
    "choc_embed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'choc_embed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20388\\2352175900.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclusterNumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;31m#@param\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mchoc_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchoc_embed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'centroid'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mclusterNumber\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'choc_embed' is not defined"
     ]
    }
   ],
   "source": [
    "clusterNumber = 20 #@param\n",
    "choc_data.loc[choc_embed['centroid']==clusterNumber,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Run cell to setup functions { display-mode: \"form\" }\n",
    "def clusterCardinality(df):\n",
    "  k = np.max(df[\"centroid\"]) + 1\n",
    "  if six.PY2:\n",
    "    k = k.astype(int)\n",
    "  print(\"Number of clusters:\"+str(k))\n",
    "  clCard = np.zeros(k)\n",
    "  for kk in range(k):\n",
    "    clCard[kk] = np.sum(df[\"centroid\"]==kk)\n",
    "  if six.PY2:\n",
    "    clCard = clCard.astype(int)\n",
    "  # print \"Cluster Cardinality:\"+str(clCard)\n",
    "  plt.figure()\n",
    "  plt.bar(range(k),clCard)\n",
    "  plt.title('Cluster Cardinality')\n",
    "  plt.xlabel('Cluster Number: '+str(0)+' to '+str(k-1))\n",
    "  plt.ylabel('Points in Cluster')\n",
    "  return clCard\n",
    "\n",
    "def clusterMagnitude(df):\n",
    "  k = np.max(df[\"centroid\"]) + 1\n",
    "  if six.PY2:\n",
    "    k = k.astype(int)\n",
    "  cl = np.zeros(k)\n",
    "  clMag = np.zeros(k)\n",
    "  for kk in range(k):\n",
    "    idx = np.where(df[\"centroid\"]==kk)\n",
    "    idx = idx[0]\n",
    "    clMag[kk] = np.sum(df.loc[idx,\"pt2centroid\"])\n",
    "  # print \"Cluster Magnitude:\",clMag #precision set using np pref\n",
    "  plt.figure()\n",
    "  plt.bar(range(k),clMag)\n",
    "  plt.title('Cluster Magnitude')\n",
    "  plt.xlabel('Cluster Number: '+str(0)+' to '+str(k-1))\n",
    "  plt.ylabel('Total Point-to-Centroid Distance')\n",
    "  return clMag\n",
    "\n",
    "def plotCardVsMag(clCard,clMag):\n",
    "  plt.figure()\n",
    "  plt.scatter(clCard,clMag)\n",
    "  plt.xlim(xmin=0)\n",
    "  plt.ylim(ymin=0)\n",
    "  plt.title('Magnitude vs Cardinality')\n",
    "  plt.ylabel('Magnitude')\n",
    "  plt.xlabel('Cardinality')\n",
    "\n",
    "def clusterQualityMetrics(df):\n",
    "  clCard = clusterCardinality(df)\n",
    "  clMag = clusterMagnitude(df)\n",
    "  plotCardVsMag(clCard,clMag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusterQualityMetrics(choc_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'choc_embed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20388\\3000879144.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mkmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m200\u001b[0m  \u001b[1;31m# @param\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mkstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m  \u001b[1;31m# @param\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mlossVsClusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchoc_embed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'choc_embed' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot loss vs number of clusters\n",
    "def lossVsClusters(kmin, kmax, kstep, choc_data):\n",
    "  kmax += 1  # include kmax-th cluster in range\n",
    "  kRange = range(kmin, kmax, kstep)\n",
    "  loss = np.zeros(len(kRange))\n",
    "  lossCtr = 0\n",
    "  for kk in kRange:\n",
    "    [choc_data, centroids] = kmeans(choc_data, kk, feature_cols, 0)\n",
    "    loss[lossCtr] = np.sum(choc_data['pt2centroid'])\n",
    "    lossCtr += 1\n",
    "  plt.scatter(kRange, loss)\n",
    "  plt.title('Loss vs Clusters Used')\n",
    "  plt.xlabel('Number of clusters')\n",
    "  plt.ylabel('Total Point-to-Centroid Distance')\n",
    "\n",
    "\n",
    "kmin = 5  # @param\n",
    "kmax = 200  # @param\n",
    "kstep = 10  # @param\n",
    "lossVsClusters(kmin, kmax, kstep, choc_embed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
